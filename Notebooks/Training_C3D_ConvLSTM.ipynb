{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "from scripts.core import *\n",
    "from fastai.learner import Learner\n",
    "import fastai\n",
    "from torch.utils.data import Dataset\n",
    "from scripts.models import *\n",
    "from scripts.learners import modelLearner, ParallelLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vid100Datasat(Dataset):\n",
    "    def __init__(self, train=True, trim_start=50, trim_end=50):\n",
    "        super().__init__()\n",
    "        import random\n",
    "        self.train=train\n",
    "        self.trim_start,self.trim_end = trim_start,trim_end\n",
    "        PTH = '/home/sufiyan/Common_data/mtp2/makeDataset/Sub Video/data/Mercedes_224_224_Manual_annonate_8sec_LSTM_short_005_'\n",
    "        PTH_L=os.path.join(PTH,\"LEFT\")\n",
    "        PTH_R=os.path.join(PTH,\"RIGHT\")\n",
    "        PTH_C=os.path.join(PTH,\"CLEAR\")\n",
    "        left_vids =[os.path.join(d,f) for d,_,fs in os.walk(PTH_L) for f in fs if f.split(\".\")[-1]=='npy']\n",
    "        right_vids=[os.path.join(d,f) for d,_,fs in os.walk(PTH_R) for f in fs if f.split(\".\")[-1]=='npy']\n",
    "        clear_vids=[os.path.join(d,f) for d,_,fs in os.walk(PTH_C) for f in fs if f.split(\".\")[-1]=='npy']\n",
    "        self.fileNames=left_vids+right_vids\n",
    "        self.fileNames=[filename for filename in self.fileNames if self.get_label(filename)[100]!=\"CLEAR\"]\n",
    "        np.random.shuffle(self.fileNames)\n",
    "     \n",
    "    @staticmethod\n",
    "    def stoi(label):\n",
    "        stoi={\"CLEAR\":0, \"LEFT\":1, \"RIGHT\":2}\n",
    "        return stoi[label]\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        X=np.load(self.fileNames[i])[self.trim_start:-self.trim_end]\n",
    "        y=self.get_label(self.fileNames[i])[self.trim_start:-self.trim_end]\n",
    "        y=np.asarray([self.stoi(label) for label in y])\n",
    "        X=np.expand_dims(X,1)\n",
    "        X=np.concatenate((X,X,X), axis=1)\n",
    "        return (torch.from_numpy(X), y)\n",
    "    def __len__(self): return len(self.fileNames)\n",
    "    \n",
    "    def get_label(self, filename):\n",
    "#         filename=self.fileNames[i]\n",
    "        if self.train:\n",
    "              return np.load(filename.replace('/data/','/label/'))\n",
    "        else: return np.load(filename.replace('/data/','/val_label/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader=torch.utils.data.DataLoader(Vid100Datasat(train=True) ,batch_size=1, shuffle=True)\n",
    "validLoader=torch.utils.data.DataLoader(Vid100Datasat(train=False),batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=ParallelLearner([modelLearner(C3D_resnet_ConvLSTM2D(3, 3), loss_fn=nn.MSELoss, optim=torch.optim.SGD, modelName=\"MSE_22Oct\", lr=0.01, is_depth=True)], trainLoader=trainLoader, validLoader=validLoader, printEvery=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.248651596294208: 100%|██████████| 132/132 [01:34<00:00,  1.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Epoch: 0   Time Elapsed: 94.49109148979187\n",
      "lr: 0.01      trainLoss: 0.248651596294208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/132 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01      MSE validationLoss: 0.19941101629625668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.1978953516844547: 100%|██████████| 132/132 [01:34<00:00,  1.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Epoch: 1   Time Elapsed: 241.57834768295288\n",
      "lr: 0.01      trainLoss: 0.1978953516844547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/132 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01      MSE validationLoss: 0.18487916661031317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.1888703667191845: 100%|██████████| 132/132 [01:39<00:00,  1.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Epoch: 2   Time Elapsed: 396.8367838859558\n",
      "lr: 0.01      trainLoss: 0.1888703667191845\n",
      "lr: 0.01      MSE validationLoss: 0.18184399418532848\n"
     ]
    }
   ],
   "source": [
    "learner.train(epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Loss: 0.1852452741992293: 100%|██████████| 132/132 [01:34<00:00,  1.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Epoch: 0   Time Elapsed: 94.41840195655823\n",
      "lr: 0.01      trainLoss: 0.1852452741992293\n",
      "lr: 0.01      MSE validationLoss: 0.1803826458300605\n"
     ]
    }
   ],
   "source": [
    "learner.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=learner.learners[0].valid_confusion_matrix_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Model has overfitted to Clear Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8132,    0,    0],\n",
       "       [2534,    0,    0],\n",
       "       [2534,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
