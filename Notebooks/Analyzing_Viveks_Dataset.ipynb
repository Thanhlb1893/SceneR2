{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.functional as F, torch.utils.data as data\n",
    "import torchvision, numpy as np, os\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.conv_learner import ConvnetBuilder\n",
    "from fastai.model import resnet34\n",
    "import nvvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/home/sufiyan/Common_data/mtp2/dataset/100_vids/\"\n",
    "PATH_L_Vids=PATH+\"LEFT/\"\n",
    "PATH_L=PATH+\"LEFT_data/\"\n",
    "PATH_L_L=PATH+\"LEFT_labels/\"\n",
    "PATH_R_Vids=PATH+\"RIGHT/\"\n",
    "PATH_R=PATH+\"RIGHT_data/\"\n",
    "PATH_R_L=PATH+\"RIGHT_labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftVids=[PATH_L+fileName for fileName in os.listdir(PATH_L) if os.path.isfile(PATH_L+fileName)]\n",
    "leftVids_L=[PATH_L_L+fileName for fileName in os.listdir(PATH_L_L) if os.path.isfile(PATH_L_L+fileName)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vidLoader(vidsList):\n",
    "    for vidName in vidsList:\n",
    "        frames=np.load(vidName)\n",
    "        for frame in frames:\n",
    "            yield frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "495\n",
      "(224, 224, 1)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(np.load(leftVids[10])))        #number of frames\n",
    "print(len(np.load(leftVids_L[10])))      #number of labels\n",
    "img=(np.load(leftVids[20])[0])\n",
    "print(img.shape)                         #shape of each frame\n",
    "print(len(img.shape))                    #dimentions\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3, 1)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "img=(np.load(leftVids[0])[0])            #Load a Frame\n",
    "print(img.shape)                         #shape of each frame\n",
    "print(len(img.shape))                    #Dimensions of frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some video have 3 channels and are unsqueezed to 1 batch size whereas some video only have N\\*M\\*1 frame shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loads resnet34 pretrained on ImageNet using fastai library, Addaptive Pool \n",
    "#Followed by Fully connected layers of 500 and c\n",
    "model=ConvnetBuilder(resnet34, c=3, is_multi=True, is_reg=False, pretrained=True).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string_to_int and int_to_string mapping\n",
    "stoi={\"w\":0, \"a\":1, \"d\":2}; itos={0:\"Clear\", 1:\"Left\", 2:\"Right\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class myVidDataset(torch.utils.data.Dataset):\n",
    "    def __init__(npArray, labelList):\n",
    "        assert isinstance(npArray, np.ndarray), \"npArray in myVidDataset should be a numpy array of Frames\"\n",
    "        assert len(npArray)==len(labelList), f\"Length of Labels {len(labelList)} not equal to len \\\n",
    "                                                    of npArray {len(npArray)}\"\n",
    "        self.frames, self.labels = npArray,labelList\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x=self.frames[idx]\n",
    "        x=np.squeeze(x)     #extra 1 dimention removed if any\n",
    "        if x.shape[-1]==1 : x=np.dstack((x,x,x)) #id image is 1 channel, make it 3 channel\n",
    "        return (x, self.labelList[idx])\n",
    "    def __len__(self): return len(self.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftVids =[PATH_L_Vids+fileName for fileName in os.listdir(PATH_L_Vids) if os.path.isfile(PATH_L_Vids+fileName)]\n",
    "rightVids=[PATH_R_Vids+fileName for fileName in os.listdir(PATH_R_Vids) if os.path.isfile(PATH_R_Vids+fileName)]\n",
    "allVids=leftVids+rightVids\n",
    "np.random.shuffle(allVids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIP_20170411_071853_Video.avi\n",
      "FLIP_20170411_071853_Video.npy\n"
     ]
    }
   ],
   "source": [
    "vidName=allVids[100].split(\"/\")[-1]                 #Video Name\n",
    "print(vidName)\n",
    "print(\".\".join(vidName.split(\".\")[:-1]+[\"npy\"]))    #Label File Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(fileName, frameNum):\n",
    "    vidName=fileName.split(\"/\")[-1]\n",
    "    labelName=\".\".join(vidName.split(\".\")[:-1]+[\"npy\"])\n",
    "    if fileName.split(\"/\")[-2]==\"RIGHT\":\n",
    "        label=list(np.load(PATH_R_L+labelName))[frameNum] \n",
    "    elif fileName.split(\"/\")[-1]==\"LEFT\":\n",
    "        label=list(np.load(PATH_L_L+labelName))[frameNum]\n",
    "    else: \n",
    "        print(f\"FileName: {fileName}   parent Folder not in [LEFT, RIGHT] returning 0 label for clear\")\n",
    "        label='w'\n",
    "    return stoi[label] #return integer corrospondinf to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sufiyan/Common_data/mtp2/dataset/100_vids/RIGHT/FLIP_20170421_002950_Video.avi'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allVids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "FatalError",
     "evalue": "Unhandled codec 13 in /home/sufiyan/Common_data/mtp2/dataset/100_vids/RIGHT/FLIP_20170421_002950_Video.avi",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFatalError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-f57915318890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnvvl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallVids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/nvvl-1.0-py3.6-linux-x86_64.egg/nvvl/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filenames, sequence_length, device_id, get_label, processing, log_level)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvvl_frame_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 print(\"NVVL WARNING: Ignoring\", f, \"because it only has\", count,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/ffi/__init__.py\u001b[0m in \u001b[0;36msafe_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m                      for arg in args)\n\u001b[1;32m    201\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mtypeof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFatalError\u001b[0m: Unhandled codec 13 in /home/sufiyan/Common_data/mtp2/dataset/100_vids/RIGHT/FLIP_20170421_002950_Video.avi"
     ]
    }
   ],
   "source": [
    "dataset=nvvl.VideoDataset(allVids, sequence_length=5, get_label=get_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Above error isn't surprising as the video have been found to be super buggy. The Metadata suggests it has 500 frames but the video have generally been found to have 49x frames and in one case even 318 frames only. A good example below--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftVids=[PATH_L+fileName for fileName in os.listdir(PATH_L) if os.path.isfile(PATH_L+fileName)]\n",
    "len(np.load(leftVids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Above video contains 498 frames rather than 500. This has been causing the problem from some time now.\n",
    "apparently, I won't be able to use Nvidia's nvvl video dataset and VidelLoader... Will have to continue with numpy array of frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to go would be to decode the videos and reencode them with a new and better supported encoder like H.264. These newly encoded videos should work fine with nvvl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video decoded and encoded again with libx264 encoder\n",
    "newVid= \"/home/sufiyan/Common_data/mtp2/dataset/100_vids/newly_encoded/LEFT/output.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=nvvl.VideoDataset([newVid], sequence_length=5, get_label=get_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the nvvl VideoDataset seems to work with the newly encoded videos. All the videos in the dataset will need to be re-encoded with H.264 to be able to use it with nvvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
